{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "5              5      116             74              0        0  25.6   \n",
      "6              3       78             50             32       88  31.0   \n",
      "7             10      115              0              0        0  35.3   \n",
      "8              2      197             70             45      543  30.5   \n",
      "9              8      125             96              0        0   0.0   \n",
      "10             4      110             92              0        0  37.6   \n",
      "11            10      168             74              0        0  38.0   \n",
      "12            10      139             80              0        0  27.1   \n",
      "13             1      189             60             23      846  30.1   \n",
      "14             5      166             72             19      175  25.8   \n",
      "15             7      100              0              0        0  30.0   \n",
      "16             0      118             84             47      230  45.8   \n",
      "17             7      107             74              0        0  29.6   \n",
      "18             1      103             30             38       83  43.3   \n",
      "19             1      115             70             30       96  34.6   \n",
      "20             3      126             88             41      235  39.3   \n",
      "21             8       99             84              0        0  35.4   \n",
      "22             7      196             90              0        0  39.8   \n",
      "23             9      119             80             35        0  29.0   \n",
      "24            11      143             94             33      146  36.6   \n",
      "25            10      125             70             26      115  31.1   \n",
      "26             7      147             76              0        0  39.4   \n",
      "27             1       97             66             15      140  23.2   \n",
      "28            13      145             82             19      110  22.2   \n",
      "29             5      117             92              0        0  34.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "738            2       99             60             17      160  36.6   \n",
      "739            1      102             74              0        0  39.5   \n",
      "740           11      120             80             37      150  42.3   \n",
      "741            3      102             44             20       94  30.8   \n",
      "742            1      109             58             18      116  28.5   \n",
      "743            9      140             94              0        0  32.7   \n",
      "744           13      153             88             37      140  40.6   \n",
      "745           12      100             84             33      105  30.0   \n",
      "746            1      147             94             41        0  49.3   \n",
      "747            1       81             74             41       57  46.3   \n",
      "748            3      187             70             22      200  36.4   \n",
      "749            6      162             62              0        0  24.3   \n",
      "750            4      136             70              0        0  31.2   \n",
      "751            1      121             78             39       74  39.0   \n",
      "752            3      108             62             24        0  26.0   \n",
      "753            0      181             88             44      510  43.3   \n",
      "754            8      154             78             32        0  32.4   \n",
      "755            1      128             88             39      110  36.5   \n",
      "756            7      137             90             41        0  32.0   \n",
      "757            0      123             72              0        0  36.3   \n",
      "758            1      106             76              0        0  37.5   \n",
      "759            6      190             92              0        0  35.5   \n",
      "760            2       88             58             26       16  28.4   \n",
      "761            9      170             74             31        0  44.0   \n",
      "762            9       89             62              0        0  22.5   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "5                       0.201   30        0  \n",
      "6                       0.248   26        1  \n",
      "7                       0.134   29        0  \n",
      "8                       0.158   53        1  \n",
      "9                       0.232   54        1  \n",
      "10                      0.191   30        0  \n",
      "11                      0.537   34        1  \n",
      "12                      1.441   57        0  \n",
      "13                      0.398   59        1  \n",
      "14                      0.587   51        1  \n",
      "15                      0.484   32        1  \n",
      "16                      0.551   31        1  \n",
      "17                      0.254   31        1  \n",
      "18                      0.183   33        0  \n",
      "19                      0.529   32        1  \n",
      "20                      0.704   27        0  \n",
      "21                      0.388   50        0  \n",
      "22                      0.451   41        1  \n",
      "23                      0.263   29        1  \n",
      "24                      0.254   51        1  \n",
      "25                      0.205   41        1  \n",
      "26                      0.257   43        1  \n",
      "27                      0.487   22        0  \n",
      "28                      0.245   57        0  \n",
      "29                      0.337   38        0  \n",
      "..                        ...  ...      ...  \n",
      "738                     0.453   21        0  \n",
      "739                     0.293   42        1  \n",
      "740                     0.785   48        1  \n",
      "741                     0.400   26        0  \n",
      "742                     0.219   22        0  \n",
      "743                     0.734   45        1  \n",
      "744                     1.174   39        0  \n",
      "745                     0.488   46        0  \n",
      "746                     0.358   27        1  \n",
      "747                     1.096   32        0  \n",
      "748                     0.408   36        1  \n",
      "749                     0.178   50        1  \n",
      "750                     1.182   22        1  \n",
      "751                     0.261   28        0  \n",
      "752                     0.223   25        0  \n",
      "753                     0.222   26        1  \n",
      "754                     0.443   45        1  \n",
      "755                     1.057   37        1  \n",
      "756                     0.391   39        0  \n",
      "757                     0.258   52        1  \n",
      "758                     0.197   26        0  \n",
      "759                     0.278   66        1  \n",
      "760                     0.766   22        0  \n",
      "761                     0.403   43        1  \n",
      "762                     0.142   33        0  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies:111\n",
      "Glucose:5\n",
      "BloodPressure:35\n",
      "SkinThickness:227\n",
      "Insulin:374\n",
      "BMI:11\n",
      "DiabetesPedigreeFunction:0\n",
      "Age:0\n",
      "Outcome:500\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    missing = df.loc[df[col]==0].shape[0]\n",
    "    print(col+ ':'+ str(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['Glucose']= df['Glucose'].replace(0, np.nan)\n",
    "df['BloodPressure']= df['BloodPressure'].replace(0, np.nan)\n",
    "df['SkinThickness']= df['SkinThickness'].replace(0, np.nan)\n",
    "df['Insulin']= df['Insulin'].replace(0, np.nan)\n",
    "df['BMI']= df['BMI'].replace(0, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "df['Glucose']= df['Glucose'].fillna(df['Glucose'].mean())\n",
    "df['BloodPressure']= df['BloodPressure'].fillna(df['BloodPressure'].mean())\n",
    "df['SkinThickness']= df['SkinThickness'].fillna(df['SkinThickness'].mean())\n",
    "df['Insulin']= df['Insulin'].fillna(df['Insulin'].mean())\n",
    "df['BMI']= df['BMI'].fillna(df['BMI'].mean())\n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "### scale the dataset \n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "df_scaled = preprocessing.scale(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "df_scaled['Outcome'] = df['Outcome']\n",
    "df= df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the dataset to training and testing datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = df.iloc[:,0:8].values\n",
    "labels = df.iloc[:,8].values\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)\n",
    "\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(train_features, train_labels, test_size = 0.2)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(32, activation='relu', input_dim=8))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "491/491 [==============================] - 1s 1ms/step - loss: 0.6555 - accuracy: 0.6436\n",
      "Epoch 2/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.6075 - accuracy: 0.6660\n",
      "Epoch 3/200\n",
      "491/491 [==============================] - 0s 70us/step - loss: 0.5683 - accuracy: 0.6945\n",
      "Epoch 4/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.5356 - accuracy: 0.7210\n",
      "Epoch 5/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.5093 - accuracy: 0.7475\n",
      "Epoch 6/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.4895 - accuracy: 0.7597\n",
      "Epoch 7/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4741 - accuracy: 0.7597\n",
      "Epoch 8/200\n",
      "491/491 [==============================] - 0s 70us/step - loss: 0.4620 - accuracy: 0.7739\n",
      "Epoch 9/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.4527 - accuracy: 0.7780\n",
      "Epoch 10/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4456 - accuracy: 0.7862\n",
      "Epoch 11/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.4402 - accuracy: 0.7902\n",
      "Epoch 12/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.4352 - accuracy: 0.7902\n",
      "Epoch 13/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.4290 - accuracy: 0.7943\n",
      "Epoch 14/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.4245 - accuracy: 0.7963\n",
      "Epoch 15/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.4208 - accuracy: 0.7963\n",
      "Epoch 16/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.4173 - accuracy: 0.7923\n",
      "Epoch 17/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.4143 - accuracy: 0.7923\n",
      "Epoch 18/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.4118 - accuracy: 0.7943\n",
      "Epoch 19/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.4084 - accuracy: 0.8004\n",
      "Epoch 20/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.4055 - accuracy: 0.8065\n",
      "Epoch 21/200\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.4036 - accuracy: 0.8065\n",
      "Epoch 22/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.4008 - accuracy: 0.8106\n",
      "Epoch 23/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3989 - accuracy: 0.8106\n",
      "Epoch 24/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.3975 - accuracy: 0.8147\n",
      "Epoch 25/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3950 - accuracy: 0.8126\n",
      "Epoch 26/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3929 - accuracy: 0.8126\n",
      "Epoch 27/200\n",
      "491/491 [==============================] - 0s 78us/step - loss: 0.3908 - accuracy: 0.8187\n",
      "Epoch 28/200\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.3900 - accuracy: 0.8187\n",
      "Epoch 29/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.3873 - accuracy: 0.8208\n",
      "Epoch 30/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3853 - accuracy: 0.8248\n",
      "Epoch 31/200\n",
      "491/491 [==============================] - 0s 81us/step - loss: 0.3835 - accuracy: 0.8289\n",
      "Epoch 32/200\n",
      "491/491 [==============================] - 0s 82us/step - loss: 0.3817 - accuracy: 0.8289\n",
      "Epoch 33/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.3799 - accuracy: 0.8289\n",
      "Epoch 34/200\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.3783 - accuracy: 0.8330\n",
      "Epoch 35/200\n",
      "491/491 [==============================] - 0s 72us/step - loss: 0.3765 - accuracy: 0.8310\n",
      "Epoch 36/200\n",
      "491/491 [==============================] - 0s 76us/step - loss: 0.3752 - accuracy: 0.8371\n",
      "Epoch 37/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3734 - accuracy: 0.8391\n",
      "Epoch 38/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.3698 - accuracy: 0.8371\n",
      "Epoch 39/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.3678 - accuracy: 0.8350\n",
      "Epoch 40/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.3664 - accuracy: 0.8411\n",
      "Epoch 41/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3642 - accuracy: 0.8411\n",
      "Epoch 42/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.3622 - accuracy: 0.8411\n",
      "Epoch 43/200\n",
      "491/491 [==============================] - 0s 70us/step - loss: 0.3628 - accuracy: 0.8391\n",
      "Epoch 44/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.3589 - accuracy: 0.8411\n",
      "Epoch 45/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.3565 - accuracy: 0.8473\n",
      "Epoch 46/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3552 - accuracy: 0.8493\n",
      "Epoch 47/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3542 - accuracy: 0.8350\n",
      "Epoch 48/200\n",
      "491/491 [==============================] - 0s 73us/step - loss: 0.3518 - accuracy: 0.8513\n",
      "Epoch 49/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3489 - accuracy: 0.8534\n",
      "Epoch 50/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3473 - accuracy: 0.8534\n",
      "Epoch 51/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.3454 - accuracy: 0.8574\n",
      "Epoch 52/200\n",
      "491/491 [==============================] - 0s 74us/step - loss: 0.3432 - accuracy: 0.8534\n",
      "Epoch 53/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.3423 - accuracy: 0.8595\n",
      "Epoch 54/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3398 - accuracy: 0.8574\n",
      "Epoch 55/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.3379 - accuracy: 0.8656\n",
      "Epoch 56/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.3367 - accuracy: 0.8635\n",
      "Epoch 57/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3347 - accuracy: 0.8615\n",
      "Epoch 58/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.3333 - accuracy: 0.8615\n",
      "Epoch 59/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3321 - accuracy: 0.8635\n",
      "Epoch 60/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.3303 - accuracy: 0.8656\n",
      "Epoch 61/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.3282 - accuracy: 0.8676\n",
      "Epoch 62/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.3260 - accuracy: 0.8676\n",
      "Epoch 63/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.3262 - accuracy: 0.8635\n",
      "Epoch 64/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.3251 - accuracy: 0.8635\n",
      "Epoch 65/200\n",
      "491/491 [==============================] - 0s 67us/step - loss: 0.3215 - accuracy: 0.8717\n",
      "Epoch 66/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.3210 - accuracy: 0.8676\n",
      "Epoch 67/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.3190 - accuracy: 0.8656\n",
      "Epoch 68/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.3169 - accuracy: 0.8737\n",
      "Epoch 69/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.3147 - accuracy: 0.8758\n",
      "Epoch 70/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.3147 - accuracy: 0.8737\n",
      "Epoch 71/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.3131 - accuracy: 0.8717\n",
      "Epoch 72/200\n",
      "491/491 [==============================] - 0s 63us/step - loss: 0.3106 - accuracy: 0.8737\n",
      "Epoch 73/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.3097 - accuracy: 0.8737\n",
      "Epoch 74/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3075 - accuracy: 0.8778\n",
      "Epoch 75/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3062 - accuracy: 0.8717\n",
      "Epoch 76/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.3047 - accuracy: 0.8697\n",
      "Epoch 77/200\n",
      "491/491 [==============================] - 0s 62us/step - loss: 0.3047 - accuracy: 0.8758\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 66us/step - loss: 0.3025 - accuracy: 0.8758\n",
      "Epoch 79/200\n",
      "491/491 [==============================] - 0s 62us/step - loss: 0.3008 - accuracy: 0.8737\n",
      "Epoch 80/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2993 - accuracy: 0.8778\n",
      "Epoch 81/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2972 - accuracy: 0.8778\n",
      "Epoch 82/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2964 - accuracy: 0.8737\n",
      "Epoch 83/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2951 - accuracy: 0.8778\n",
      "Epoch 84/200\n",
      "491/491 [==============================] - 0s 70us/step - loss: 0.2937 - accuracy: 0.8717\n",
      "Epoch 85/200\n",
      "491/491 [==============================] - 0s 65us/step - loss: 0.2926 - accuracy: 0.8737\n",
      "Epoch 86/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.2905 - accuracy: 0.8839\n",
      "Epoch 87/200\n",
      "491/491 [==============================] - 0s 69us/step - loss: 0.2894 - accuracy: 0.8798\n",
      "Epoch 88/200\n",
      "491/491 [==============================] - 0s 64us/step - loss: 0.2883 - accuracy: 0.8798\n",
      "Epoch 89/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.2877 - accuracy: 0.8798\n",
      "Epoch 90/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.2856 - accuracy: 0.8819\n",
      "Epoch 91/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.2852 - accuracy: 0.8859\n",
      "Epoch 92/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.2841 - accuracy: 0.8921\n",
      "Epoch 93/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.2826 - accuracy: 0.8819\n",
      "Epoch 94/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2803 - accuracy: 0.8859\n",
      "Epoch 95/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2787 - accuracy: 0.8900\n",
      "Epoch 96/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2772 - accuracy: 0.8900\n",
      "Epoch 97/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2751 - accuracy: 0.8900\n",
      "Epoch 98/200\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.90 - 0s 53us/step - loss: 0.2755 - accuracy: 0.8880\n",
      "Epoch 99/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2739 - accuracy: 0.8941\n",
      "Epoch 100/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2714 - accuracy: 0.8880\n",
      "Epoch 101/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2716 - accuracy: 0.8880\n",
      "Epoch 102/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2701 - accuracy: 0.8961\n",
      "Epoch 103/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2681 - accuracy: 0.8921\n",
      "Epoch 104/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2664 - accuracy: 0.8880\n",
      "Epoch 105/200\n",
      "491/491 [==============================] - 0s 70us/step - loss: 0.2654 - accuracy: 0.8921\n",
      "Epoch 106/200\n",
      "491/491 [==============================] - 0s 68us/step - loss: 0.2640 - accuracy: 0.8859\n",
      "Epoch 107/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.2625 - accuracy: 0.8880\n",
      "Epoch 108/200\n",
      "491/491 [==============================] - 0s 66us/step - loss: 0.2621 - accuracy: 0.8921\n",
      "Epoch 109/200\n",
      "491/491 [==============================] - 0s 71us/step - loss: 0.2619 - accuracy: 0.8961\n",
      "Epoch 110/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2590 - accuracy: 0.8900\n",
      "Epoch 111/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2590 - accuracy: 0.8941\n",
      "Epoch 112/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2573 - accuracy: 0.8900\n",
      "Epoch 113/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2559 - accuracy: 0.8941\n",
      "Epoch 114/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2547 - accuracy: 0.8900\n",
      "Epoch 115/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2531 - accuracy: 0.8961\n",
      "Epoch 116/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2521 - accuracy: 0.8941\n",
      "Epoch 117/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.2517 - accuracy: 0.9002\n",
      "Epoch 118/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2490 - accuracy: 0.8941\n",
      "Epoch 119/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.2497 - accuracy: 0.8982\n",
      "Epoch 120/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2481 - accuracy: 0.8961\n",
      "Epoch 121/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.2475 - accuracy: 0.8961\n",
      "Epoch 122/200\n",
      "491/491 [==============================] - 0s 61us/step - loss: 0.2454 - accuracy: 0.8941\n",
      "Epoch 123/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2443 - accuracy: 0.8982\n",
      "Epoch 124/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2443 - accuracy: 0.9022\n",
      "Epoch 125/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2408 - accuracy: 0.9002\n",
      "Epoch 126/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2398 - accuracy: 0.9022\n",
      "Epoch 127/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.2386 - accuracy: 0.9002\n",
      "Epoch 128/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2383 - accuracy: 0.9022\n",
      "Epoch 129/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2374 - accuracy: 0.9022\n",
      "Epoch 130/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2355 - accuracy: 0.8982\n",
      "Epoch 131/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2348 - accuracy: 0.8982\n",
      "Epoch 132/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.2334 - accuracy: 0.9043\n",
      "Epoch 133/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2318 - accuracy: 0.9022\n",
      "Epoch 134/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2312 - accuracy: 0.9002\n",
      "Epoch 135/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2318 - accuracy: 0.9022\n",
      "Epoch 136/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2301 - accuracy: 0.9043\n",
      "Epoch 137/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2284 - accuracy: 0.9022\n",
      "Epoch 138/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2268 - accuracy: 0.9063\n",
      "Epoch 139/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2255 - accuracy: 0.9022\n",
      "Epoch 140/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2252 - accuracy: 0.9063\n",
      "Epoch 141/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2235 - accuracy: 0.9043\n",
      "Epoch 142/200\n",
      "491/491 [==============================] - 0s 96us/step - loss: 0.2227 - accuracy: 0.9002\n",
      "Epoch 143/200\n",
      "491/491 [==============================] - 0s 60us/step - loss: 0.2220 - accuracy: 0.9063\n",
      "Epoch 144/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2201 - accuracy: 0.9084\n",
      "Epoch 145/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2193 - accuracy: 0.9002\n",
      "Epoch 146/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2191 - accuracy: 0.9043\n",
      "Epoch 147/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2168 - accuracy: 0.9043\n",
      "Epoch 148/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.2169 - accuracy: 0.9043\n",
      "Epoch 149/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2166 - accuracy: 0.9084\n",
      "Epoch 150/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2144 - accuracy: 0.9084\n",
      "Epoch 151/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2136 - accuracy: 0.9145\n",
      "Epoch 152/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2143 - accuracy: 0.9063\n",
      "Epoch 153/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2110 - accuracy: 0.9104\n",
      "Epoch 154/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2098 - accuracy: 0.9124\n",
      "Epoch 155/200\n",
      "491/491 [==============================] - 0s 52us/step - loss: 0.2100 - accuracy: 0.9043\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 59us/step - loss: 0.2101 - accuracy: 0.9145\n",
      "Epoch 157/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.2073 - accuracy: 0.9084\n",
      "Epoch 158/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2070 - accuracy: 0.9084\n",
      "Epoch 159/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.2058 - accuracy: 0.9145\n",
      "Epoch 160/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2038 - accuracy: 0.9185\n",
      "Epoch 161/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.2027 - accuracy: 0.9185\n",
      "Epoch 162/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2026 - accuracy: 0.9104\n",
      "Epoch 163/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.2008 - accuracy: 0.9185\n",
      "Epoch 164/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2004 - accuracy: 0.9165\n",
      "Epoch 165/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.2023 - accuracy: 0.9043\n",
      "Epoch 166/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.2004 - accuracy: 0.9145\n",
      "Epoch 167/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.1973 - accuracy: 0.9165\n",
      "Epoch 168/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1974 - accuracy: 0.9165\n",
      "Epoch 169/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.1982 - accuracy: 0.9165\n",
      "Epoch 170/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1938 - accuracy: 0.9185\n",
      "Epoch 171/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1945 - accuracy: 0.9185\n",
      "Epoch 172/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1933 - accuracy: 0.9185\n",
      "Epoch 173/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1929 - accuracy: 0.9185\n",
      "Epoch 174/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.1910 - accuracy: 0.9226\n",
      "Epoch 175/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1910 - accuracy: 0.9124\n",
      "Epoch 176/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1923 - accuracy: 0.9185\n",
      "Epoch 177/200\n",
      "491/491 [==============================] - 0s 53us/step - loss: 0.1903 - accuracy: 0.9185\n",
      "Epoch 178/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.1883 - accuracy: 0.9185\n",
      "Epoch 179/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1870 - accuracy: 0.9206\n",
      "Epoch 180/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1866 - accuracy: 0.9185\n",
      "Epoch 181/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1874 - accuracy: 0.9185\n",
      "Epoch 182/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1870 - accuracy: 0.9206\n",
      "Epoch 183/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1845 - accuracy: 0.9287\n",
      "Epoch 184/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.1835 - accuracy: 0.9226\n",
      "Epoch 185/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1835 - accuracy: 0.9246\n",
      "Epoch 186/200\n",
      "491/491 [==============================] - 0s 58us/step - loss: 0.1821 - accuracy: 0.9246\n",
      "Epoch 187/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1820 - accuracy: 0.9246\n",
      "Epoch 188/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1800 - accuracy: 0.9226\n",
      "Epoch 189/200\n",
      "491/491 [==============================] - 0s 57us/step - loss: 0.1782 - accuracy: 0.9267\n",
      "Epoch 190/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1799 - accuracy: 0.9206\n",
      "Epoch 191/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1787 - accuracy: 0.9287\n",
      "Epoch 192/200\n",
      "491/491 [==============================] - 0s 59us/step - loss: 0.1766 - accuracy: 0.9246\n",
      "Epoch 193/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1770 - accuracy: 0.9246\n",
      "Epoch 194/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1772 - accuracy: 0.9246\n",
      "Epoch 195/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1760 - accuracy: 0.9267\n",
      "Epoch 196/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1744 - accuracy: 0.9287\n",
      "Epoch 197/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1725 - accuracy: 0.9267\n",
      "Epoch 198/200\n",
      "491/491 [==============================] - 0s 54us/step - loss: 0.1727 - accuracy: 0.9328\n",
      "Epoch 199/200\n",
      "491/491 [==============================] - 0s 56us/step - loss: 0.1734 - accuracy: 0.9267\n",
      "Epoch 200/200\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.1717 - accuracy: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2290d4aa8d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, train_labels, epochs =200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 216us/step\n",
      "[0.1694599052856993, 0.9307535886764526]\n",
      "154/154 [==============================] - 0s 32us/step\n",
      "[0.8872696842466082, 0.7402597665786743]\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(train_features, train_labels)\n",
    "print(train_score)\n",
    "\n",
    "test_score = model.evaluate(test_features, test_labels )\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83 20]\n",
      " [20 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "prediction = model.predict_classes(test_features)\n",
    "\n",
    "print(confusion_matrix(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
